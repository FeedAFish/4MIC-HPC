---
fontsize: 12pt
classoption: xcolor = usenames,dvipsnames
output:
  bookdown::pdf_document2:
    papersize: a4
    fig_caption: true
    highlight: tango
    keep_tex: true
    number_sections: true
    pandoc_args: --listings
    toc_depth: 3
    toc: false
    latex_engine: xelatex
    includes:
      in_header: preamble.tex
      before_body: blas_cover.tex
---

```{r include=FALSE}
library(kableExtra)
library(dplyr)
library(stringi)

knitr::opts_chunk$set(fig.align = "center")
options(width=80)

library(reticulate)
use_python("/Users/vovannghia/programming/.venvs/sci/bin/python")

to_float_str <- function(num) {
  return(gsub("\\.", ",", num))
}
```

```{python include=FALSE}
import itertools
import os
import subprocess
import sys

import numpy as np
import pandas as pd


def init_matrix(nrow: int, ncol: int, coff: float):
    m = np.empty((nrow, ncol))
    for i in range(nrow):
        for j in range(ncol):
            m[i, j] = coff * (i + 1 + j + 1) / nrow / ncol
    return m


def pmatrix(a: np.ndarray):
    if len(a.shape) != 2:
        raise ValueError("pmatrix can only display two dimensions")
    latex = r"\begin{pmatrix}" + "\n"
    nrow, ncol = a.shape
    for i in range(nrow):
        for j in range(ncol):
            fraction, integer = np.modf(a[i, j])
            if fraction == 0:
                latex += str(int(integer))
            else:
                latex += str(a[i, j]).replace(".", ",")
            if j != ncol - 1:
                latex += " && "
        if i != nrow - 1:
            latex += r"\\" + "\n"
    latex += "\n" + r"\end{pmatrix}"
    return latex


def compile_and_run(
    M: int = 4,
    K: int = 8,
    N: int = 4,
    block: int = 4,
    omp: bool = True,
    num_threads=None,
    schedule=None,
    raw_only=False,
    need_cache=True,
    **kwargs,
):
    command = "clang" if sys.platform == "darwin" else "gcc"
    args = [command, "-o", "blas3", "blas3.c", "-O3", "-lblas", "-fopenmp", "-lm"]

    args.append(f"-D M_HPC={M}")
    args.append(f"-D K_HPC={K}")
    args.append(f"-D N_HPC={N}")
    args.append(f"-D BLOCK_HPC={block}")

    if not kwargs.get("printarray"):
        args.append("-D NO_PRINT_ARRAY")
    if not omp:
        args.append("-D NO_OMP")

    if not need_cache and not kwargs.get("naive"):
        args.append("-D NO_NAIVE_DOT")
    if not need_cache and not kwargs.get("saxpy"):
        args.append("-D NO_SAXPY_DOT")
    if not need_cache and not kwargs.get("blocking"):
        args.append("-D NO_BLOCKING_DOT")
    if not need_cache and not kwargs.get("blas"):
        args.append("-D NO_BLAS_DOT")

    if sys.platform == "darwin":
        args += [
            "-I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Headers/",
            "-L/usr/local/Cellar/llvm/13.0.0_2/lib/",
        ]

    subprocess.run([" ".join(args)], shell=True)

    raw_output = ""
    log_path = f".local.{M}.{K}.{N}.{block}.{omp}.{num_threads}.{schedule}.log"
    if os.path.exists(log_path):
        with open(log_path, "r") as f:
            raw_output = f.read()
    else:
        run_envs = os.environ.copy()
        if num_threads:
            run_envs["OMP_NUM_THREADS"] = str(num_threads)
        if schedule:
            run_envs["OMP_SCHEDULE"] = schedule
        raw_output = subprocess.run(
            "./blas3", capture_output=True, env=run_envs
        ).stdout.decode("utf-8")
        if need_cache:
            with open(log_path, "w") as f:
                f.write(raw_output)

    if raw_only:
        return raw_output

    outputs = raw_output.splitlines()
    res = []
    i = 0
    num_threads = 0
    schedule = ""
    chunk = 0
    while i < len(outputs):
        output = outputs[i].strip()
        if output.startswith("Parallel execution with a maximum of "):
            raw_num_threads = output[len("Parallel execution with a maximum of ") :]
            num_threads = int(
                "".join(itertools.takewhile(str.isdigit, raw_num_threads))
            )
        elif output.startswith("Scheduling "):
            lhs, rhs = output.split(" = ")
            raw_schedule = lhs[len("Scheduling ") :]
            schedule = "".join(itertools.takewhile(str.isalpha, raw_schedule))
            chunk = int(rhs)
        elif output.startswith("Total time "):
            lhs, rhs = output.split(" = ")
            name = lhs[len("Total time ") :].strip().capitalize()
            if kwargs.get(name.lower()):
                time = float(rhs)
                lhs, rhs = outputs[i - 1].strip().split(" = ")
                norm = float(rhs)
                lhs, rhs = outputs[i + 1].strip().split(" = ")
                gflops = float(rhs)
                res.append(
                    {
                        "Technique": name,
                        "Time": time,
                        "Norm": norm,
                        "Gflops": gflops,
                        "M": M,
                        "K": K,
                        "N": N,
                        "Block": block,
                        "OMP": omp,
                        "Threads": num_threads,
                        "Schedule": schedule,
                        "Chunk": chunk,
                    }
                )
            i = i + 2
            continue
        i = i + 1
    df = pd.DataFrame(res)
    return df, raw_output

```

# Techniques
## Naive dot

We first mention here the original `naive_dot` function. This function serves as an anchor (or base case) for performance comparision as well as for making sure we have the right result when using other techniques.

```{c, eval=FALSE}
for (i = 0; i < M; i++)
  for (j = 0; j < N; j++)
    for (k = 0; k < K; k++) C[i + ldc * j] += A[i + lda * k] * B[k + ldb * j];
```

Below is the output of `naive_dot` for `M = 1`, `K = 2`, `N = 2`:
```{python echo=FALSE}
print(
  compile_and_run(
    1, 2, 2, omp=False, raw_only=True, printarray=True, naive=True, need_cache=False
  )
)
```
As
$$
```{python results="asis", echo=FALSE}
naive_a = init_matrix(1, 2, 1)
naive_b = init_matrix(2, 2, 2)
print(pmatrix(naive_a) + pmatrix(naive_b) + "=" + pmatrix(naive_a @ naive_b))
```
$$
The result of this function is correct. We could move on to the next technique.

## Spatial locality

Spatial locality refers to the following scenario: if a particular storage location is referenced at a particular time, then it is likely that nearby memory locations will be referenced in the near future. In order to take advantages of this property, we notice that:

  - In memory, `A`, `B`, `C` are stored in contiguous memory block.
  - When using the index order `i`, `j`, `k`, we access `B` consecutively (as we access `B` by `B[k + ldb * j]`), but not `A` and `C`.
  - Data from `A`, `B`, `C` are loaded in a memory block consisting of severals consecutive elements to cache. Thus, we could make use of spatial locality when reading data continously.

From 3 points above, we decide to switch the index order to `k`, `j`, `i`. Now we see that both reading and writing operations on `C` are in cache, this brings us a critical gain in performance. In addition, reading operations on `A` are in cache too but those on `B` are not.
```{c, eval=FALSE}
for (k = 0; k < K; k++)
  for (j = 0; j < N; j++)
    for (i = 0; i < M; i++) C[i + ldc * j] += A[i + lda * k] * B[k + ldb * j];
```

For comparision, we have a table below with small `M`, `K`, `N` (`OMP` indicates if we enable `Open MP` or not).
```{python include=FALSE}
small_naive_saxpy_df, small_naive_saxpy_output = compile_and_run(
  4, 8, 4, omp=False, printarray=True, naive=True, saxpy=True
)
```
```{r echo=FALSE}
py$small_naive_saxpy_df %>%
  select(-c("Block", "Threads", "Schedule", "Chunk")) %>%
  mutate(OMP = ifelse(OMP, "T", "F")) %>%
  kbl(
    booktabs = T,
    format.args = list(scientific = FALSE)
  ) %>% 
  kable_styling(latex_options = c("hold_position", "scale_down"))
```

We have the frobenius norm of both techniques are `r to_float_str(py$small_naive_saxpy_df$Norm[1])`, which indicate we have the right computation result. In addition, calculating time is already significantly small ($\approx$ 0 second in both methods) and the difference between these two can therefore be ommited.

However, if we set `M`, `K`, `N` to 2048. There will be a huge performance gain as in the table shown below.
```{python include=FALSE}
M = 2048
K = 2048
N = 2048
big_naive_saxpy_df, big_naive_saxpy_output = compile_and_run(
  2048, 2048, 2048, omp=False, printarray=False, naive=True, saxpy=True
)
```
```{r echo=FALSE}
py$big_naive_saxpy_df %>%
  select(-c("Block", "Threads", "Schedule", "Chunk")) %>%
  mutate(OMP = ifelse(OMP, "T", "F")) %>%
  kbl(
    booktabs = T,
    format.args = list(scientific = FALSE)
  ) %>% 
  kable_styling(latex_options = c("hold_position", "scale_down"))
```

Here, the `naive_dot` function is approximately `r round(py$big_naive_saxpy_df$Time[1]/py$big_naive_saxpy_df$Time[2])` times slower than the `saxpy_dot` function.

## OpenMP parallelization

For parallelism, we add a directive `#pragma omp` as well as additional clauses and wrap the code which we want to parallize inside a double bracket `{}`. A link to github with full source code will be provided at the end of the report. For performance comparision, we will study it in the next sections.

## Cache blocking